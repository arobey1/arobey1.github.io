<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/x-icon" href="../img/icons/soccerball.png">

    <title>Alex Robey :: Research</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <div class="container">
        <header>
            <div class="navbar">
                <a href="../../" class="brand">Alex Robey</a>
                <nav>
                    <ul>
                        <li><a href="../bio/">bio</a></li>
                        <li><a href="../research/" class="active">research</a></li>
                        <li><a href="../teaching/">teaching</a></li>
                        <li><a href="../writing/">writing</a></li>
                        <li><a href="../files/cv.pdf" target="_blank">cv</a></li>
                    </ul>
                </nav>
            </div>
        </header>
        
        <main>

            <script>
                document.querySelectorAll('.scroll-link').forEach(anchor => {
                    anchor.addEventListener('click', function (e) {
                        e.preventDefault();
                        console.log("hello");
                        document.querySelector(this.getAttribute('href')).scrollIntoView({
                            behavior: 'smooth'
                        });
                    });
                });
            </script>
            

            <div class="jump-container">
                <p>
                    <a href="#research-section" class="scroll-link">[research]</a> 
                    <a href="#focus-area-section" class="scroll-link">[focus areas]</a> 
                    <a href="#publications-section" class="scroll-link">[publications]</a>
                </p>
            </div>

            <div class="research-section" id="research-section">
                <h2 class="section-heading"><span>Research</span></h2>
                <p>
                    My goal is to make AI safe for people to use. Because modern AIs are so complex and capable, finding ways to make AI safe involves tools from different areas of math, statistics, and engineering. 
                </p>
            </div>

            <div class="focus-area-section" id="focus-area-section">

                <h2 class="section-heading"><span>Focus Areas</span></h2>

                <div class="focus-area-item">
                    <h4 class="focus-subtitle">1. AI safety</h3>
                    <p>
                        Making text generation models like OpenAI's ChatGPT safe for humans to use is a problem that cannot be solved by algorithms alone. A collective effort to adjust the governance of AI, design content filters, continuously monitor and probe the vulnerabilites is needed. 
                    </p>

                    <figure class="research-image-with-caption">
                        <img src="../img/research/aisafety.png" id="aisafety-image" alt="Nominal LLM GIF" class="wide-image">
                        <figcaption><span class="figure-label"></span>Large language models, like OpenAI's ChatGPT, are vulnerable to attacks that cause these models to generate harmful content.</figcaption>
                    </figure>

                    <p>
                        The technical part of my research agenda is to design <a href="https://arxiv.org/abs/2310.08419" target="_blank">attacks</a>, <a href="https://arxiv.org/abs/2310.03684" target="_blank">defenses</a>, and <a href="https://arxiv.org/pdf/2404.01318">benchmarks</a> to stress test large models that process text, images, and speech. I'm also interested in (1) understanding the mechanisms and data that cause large models to generate harmful content and (2) measuring the vulnerabilities of large models when used in fields like robotics.
                    </p>

                    <figure class="research-image-with-caption">
                        <img src="../img/research/smoothllm.png" id="smoothllm-image" alt="Nominal LLM GIF" class="wide-image">
                        <figcaption><span class="figure-label"></span>SmoothLLM defends large language models against adversarial attacks.</figcaption>
                    </figure>

                    <p>
                        Outside of academia, I'm interested in contributing to the ongoing debate about how AI models should be goverened. I was recently part of a <a href="https://arxiv.org/abs/2403.04893" target="_blank">public policy proposal</a> and <a href="https://sites.mit.edu/ai-safe-harbor/" target="_blank"> open letter</a>, which were later covered in <a href="https://www.washingtonpost.com/technology/2024/03/05/ai-research-letter-openai-meta-midjourney/" target="_blank">The Washington Post</a>, calling for more robust oversight of large models.
                    </p>
                </div>
                
                <div class="focus-area-item">
                    <h4 class="focus-subtitle">2. Out-of-distribution generalization</h3>
                    <p>
                        Deep learning has an amazing capacity to recognize and interpret the data it sees during training. But what happens when neural networks interacts with data very different from what they've seen before?
                    </p>

                    <figure class="research-image-with-caption">
                        <img src="../img/research/mbdg.png" alt="Nominal LLM GIF" class="wide-image">
                        <figcaption><span class="figure-label"></span>An overview of out-of-distribution generalization in medical imaging.</figcaption>
                    </figure>

                    <p>
                        This problem is called out-of-distribution (OOD) generalization. My work in this area, which uses tools from robust optimization theory and generative models, has looked at OOD problems in <a href="https://arxiv.org/pdf/2005.10247" target="_blank">self-driving</a>, <a href="https://proceedings.neurips.cc/paper/2021/file/a8f12d9486cbcc2fe0cfc5352011ad35-Paper.pdf" target="_blank">medical imaging</a>, and <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/6f11132f6ecbbcafafdf6decfc98f7be-Paper-Conference.pdf" target="_blank">drug discovery</a>. I am also interested in algorithms that yield <a href="https://ieeexplore.ieee.org/document/10136136" target="_blank"><em>provable</em> guarantees</a> on the performance of models when evaluated OOD.
                    </p>
                </div>

                <div class="focus-area-item">
                    <h4 class="focus-subtitle">3. Adversarial Robustness</h3>
                    <p>
                        Much has been written about the the tendency of neural networks to make incorrect predictions when their input data is perturbed by a malicious, or even adversarial, user. Despite <a href="https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html">thousands of papers on the topic</a>, it remains unclear how to make neural networks more robust. 
                    </p>

                    <figure class="research-image-with-caption">
                        <img src="../img/research/dists.png" alt="Nominal LLM GIF" class="wide-image">
                        <figcaption><span class="figure-label"></span>View of adversarial robustness from the dual perspective.</figcaption>
                    </figure>

                    <p>
                        My work on robustness is guided my two mantras:
                    </p>
                    <ul class="focus-list">
                        <li>Designing robust defences requires first identifying strong attacks.</li>
                        <li>Vulnerabilites should be identified, open-sourced, and resolved as fast as possible, but no faster.</li>
                    </ul>
                    <p>
                        I'm interested in designing new attacks and defenses for neural networks in the setting of perturbation-based, norm-bounded adversaries, and in understanding the fundamental, statistical limits of how robust different architectures can be. My research involves <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/312ecfdfa8b239e076b114498ce21905-Paper.pdf" target="_blank">duality-inspired defense algorithms</a> and <a href="https://proceedings.mlr.press/v162/robey22a/robey22a.pdf" target="_blank">probabilisitc views robustness</a>.
                    </p>
                </div>

            </div>

            <div class="publications-section" id="publications-section">
                <h2 class="section-heading"><span>Publications</span></h2>

                <div id="publications-container"></div>

                <!-- Jailbreaking LLM-Controlled Robots -->

                <div class="publication">
                    <img src="../img/paper-icons/unitree-go2.png" alt="JailbreakBench" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Jailbreaking LLM-Controlled Robots
                        </p>
                        <p class="publication-authors">
                            Alexander Robey, Zachary Ravichandran, Vijay Kumar, Hamed Hassani, George J. Pappas
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2410.13691" target="_blank">arXiv</a> |
                                <!-- <a href="https://github.com/arobey1/RoboPAIR" target="_blank">code</a> | -->
                                <a href="https://robopair.org">website</a> |
                                <a href="https://arobey1.github.io/writing/jailbreakingrobots.html" target="_blank">my blog</a> |
                                <a href="https://blog.ml.cmu.edu/2024/10/29/jailbreaking-llm-controlled-robots/" target="_blank">CMU MLD blog</a> |
                                <a href="https://garymarcus.substack.com/p/when-it-comes-to-security-llms-are" target="_blank">Gary Marcus's blog</a> |
                                <a href="https://www.independent.co.uk/tech/ai-artificial-intelligence-safe-vulnerability-robot-b2631080.html" target="_blank">Independent article</a> |
                                <a href="https://ai.seas.upenn.edu/news/penn-engineering-research-discovers-critical-vulnerabilities-in-ai-enabled-robots-to-increase-safety-and-security/"  target="_blank">Penn press release</a> |
                                <a href="https://spectrum.ieee.org/jailbreak-llm" target="_blank">IEEE Spectrum article</a> |
                                <a href="https://fortune.com/2024/11/12/legal-tech-robin-ai-raises-25-million-series-b-plus-llm/" target="_blank">Fortune article</a> |
                                <a href="javascript:void(0);" class="bibtex-link" >bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Under review
                            </span>
                        </div>
                    </div>
                </div>
                
                <div class="bibtex-box" style="display: none;">
                    <p>
                        @article{robey2024jailbreaking,
                            title={Jailbreaking LLM-Controlled Robots},
                            author={Robey, Alexander and Ravichandran, Zachary and Kumar, Vijay and Hassani, Hamed and Pappas, George J.},
                            journal={arXiv preprint arXiv:2410.13691},
                            year={2024}
                        }
                    </p>
                </div>


                <!-- JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models -->


                <div class="publication">
                    <img src="../img/paper-icons/jbb.png" alt="JailbreakBench" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models
                        </p>
                        <p class="publication-authors">
                            Patrick Chao*, Edoardo Debenedetti*, Alexander Robey*, Maksym Andriushchenko*, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nicolas Flammarion, George J. Pappas, Florian Tramer, Hamed Hassani, Eric Wong
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2404.01318" target="_blank">arXiv</a> |
                                <a href="https://github.com/JailbreakBench/jailbreakbench" target="_blank">code</a> |
                                <a href="https://jailbreakbench.github.io/" target="_blank">leaderboard</a> |
                                <a href="https://huggingface.co/datasets/JailbreakBench/JBB-Behaviors" target="_blank">dataset</a> |
                                <a href="javascript:void(0);" class="bibtex-link" >bibtex</a>
                            </span>
                            <span class="publication-venue">
                                NeurIPS 2024
                            </span>
                        </div>
                    </div>
                </div>
                
                <div class="bibtex-box" style="display: none;">
                    <p>
                        @article{chao2024jailbreakbench,
                            title={Jailbreakbench: An open robustness benchmark for jailbreaking large language models},
                            author={Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Pappas, George J. and Tramer, Florian and others},
                            journal={Advances in Neural Information Processing Systems},
                            volume={37},
                            year={2024}
                        }
                    </p>
                </div>

                <!-- Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation -->
                
                <div class="publication">
                    <img src="../img/paper-icons/prism.png" alt="Text-to-image" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation
                        </p>
                        <p class="publication-authors">
                            Yutong He, Alexander Robey, Naoki Murata, Yiding Jiang, Joshua Williams, George J. Pappas, Hamed Hassani, Yuki Mitsufuji, Ruslan Salakhutdinov, J. Zico Kolter
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org" target="_blank">arXiv</a> |
                                <a href="https://github.com" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Under review
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{he2024automated,
                        title={Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation},
                        author={He, Yutong and Robey, Alexander and Murata, Naoki and Jiang, Yiding and Williams, Joshua and Pappas, George J. and Hassani, Hamed and Mitsufuji, Yuki and Salakhutdinov, Ruslan and Kolter, J Zico},
                        journal={arXiv preprint arXiv:2403.19103},
                        year={2024}
                      }</p>
                </div>

                <!-- A Safe Harbor for AI Evaluation and Red Teaming -->
                
                <div class="publication">
                    <img src="../img/paper-icons/safeharbor.jpeg" alt="Safe Harbor" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            A Safe Harbor for AI Evaluation and Red Teaming
                        </p>
                        <p class="publication-authors">
                            Shayne Longpre, Sayash Kapoor, Kevin Klyman, Ashwin Ramaswami, Rishi Bommasani, Borhane Blili-Hamelin, Yangsibo Huang, Aviya Skowron, Zheng-Xin Yong, Suhas Kotha, Yi Zeng, Weiyan Shi, Xianjun Yang, Reid Southen, Alexander Robey, Patrick Chao, Diyi Yang, Ruoxi Jia, Daniel Kang, Sandy Pentland, Arvind Narayanan, Percy Liang, Peter Henderson                        
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2403.04893" target="_blank">arXiv</a> |
                                <a href="https://www.aisnakeoil.com/p/a-safe-harbor-for-independent-ai" target="_blank">AI Snake Oil blog</a> |
                                <a href="https://knightcolumbia.org/blog/a-safe-harbor-for-ai-evaluation-and-red-teaming" target="_blank">Knight Institute blog</a> |
                                <a href="https://www.washingtonpost.com/technology/2024/03/05/ai-research-letter-openai-meta-midjourney/" target="_blank">WaPo article</a> |
                                <a href="https://venturebeat.com/ai/experts-call-for-legal-safe-harbor-so-researchers-journalists-and-artists-can-evaluate-ai-tools/" target="_blank">VentureBeat article</a> |
                                <a href="https://sites.mit.edu/ai-safe-harbor/" target="_blank">open letter</a> | 
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                ICML 2024 (Oral)
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{longpre2024safe,
                        title={A safe harbor for ai evaluation and red teaming},
                        author={Longpre, Shayne and Kapoor, Sayash and Klyman, Kevin and Ramaswami, Ashwin and Bommasani, Rishi and Blili-Hamelin, Borhane and Huang, Yangsibo and Skowron, Aviya and Yong, Zheng-Xin and Kotha, Suhas and others},
                        booktitle={International Conference on Machine Learning},
                        year={2024},
                        organization={PMLR}
                      }</p>
                </div>              
                
                <!-- Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing -->

                <div class="publication">
                    <img src="../img/paper-icons/semanticsmoothing.png" alt="Semantic smoothing" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing
                        </p>
                        <p class="publication-authors">
                            Jiabao Ji*, Bairu Hou*, Alexander Robey*, George J. Pappas, Hamed Hassani, Yang Zhang, Eric Wong, Shiyu Chang
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2402.16192" target="_blank">arXiv</a> |
                                <a href="https://github.com/UCSB-NLP-Chang/SemanticSmooth" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Under review
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{ji2024defending,
                        title={Defending large language models against jailbreak attacks via semantic smoothing},
                        author={Ji, Jiabao and Hou, Bairu and Robey, Alexander and Pappas, George J. and Hassani, Hamed and Zhang, Yang and Wong, Eric and Chang, Shiyu},
                        journal={arXiv preprint arXiv:2402.16192},
                        year={2024}
                      }</p>
                </div>

                <!-- Data-Driven Modeling and Verification of Perception-Based Autonomous Systems -->

                <div class="publication">
                    <img src="../img/paper-icons/mb-closedloop.png" alt="Model-based verification" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Data-Driven Modeling and Verification of Perception-Based Autonomous Systems
                        </p>
                        <p class="publication-authors">
                            Thomas Waite, Alexander Robey, Hassani Hamed, George J. Pappas, Radoslav Ivanov
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2312.06848" target="_blank">arXiv</a> |
                                <a href="https://github.com/waite116/MountainCarVerification" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Under review
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{waite2023data,
                        title={Data-Driven Modeling and Verification of Perception-Based Autonomous Systems},
                        author={Waite, Thomas and Robey, Alexander and Hamed, Hassani and Pappas, George J. and Ivanov, Radoslav},
                        journal={arXiv preprint arXiv:2312.06848},
                        year={2023}
                      }</p>
                </div>

                <!-- Jailbreaking Black Box Large Language Models in Twenty Queries -->

                <div class="publication">
                    <img src="../img/paper-icons/pair.png" alt="PAIR" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Jailbreaking Black Box Large Language Models in Twenty Queries
                        </p>
                        <p class="publication-authors">
                            Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J. Pappas, Eric Wong
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2310.08419" target="_blank">arXiv</a> |
                                <a href="https://github.com/patrickrchao/JailbreakingLLMs" target="_blank">code</a> |
                                <a href="https://venturebeat.com/ai/new-method-reveals-how-one-llm-can-be-used-to-jailbreak-another/" target="_blank">VentureBeat article</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Under review
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{chao2023jailbreaking,
                        title={Jailbreaking black box large language models in twenty queries},
                        author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J. and Wong, Eric},
                        journal={arXiv preprint arXiv:2310.08419},
                        year={2023}
                      }</p>
                </div>
                
                <!-- SmoothLLM: Defending Large Language Models against Jailbreaking Attacks -->

                <div class="publication">
                    <img src="../img/paper-icons/smoothllm.jpg" alt="SmoothLLM" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            SmoothLLM: Defending Large Language Models against Jailbreaking Attacks
                        </p>
                        <p class="publication-authors">
                            Alexander Robey, Eric Wong, Hamed Hassani, George J. Pappas
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2310.03684" target="_blank">arXiv</a> |
                                <a href="https://github.com/arobey1/smooth-llm" target="_blank">code</a> |
                                <a href="https://debugml.github.io/smooth-llm/" target="_blank">DebugML blog</a> | 
                                <a href="https://penntoday.upenn.edu/news/ai-can-write-wedding-toast-or-summarize-paper-what-happens-when-its-asked-build-bomb" target="_blank">Penn article</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Under review
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2023smoothllm,
                        title={Smoothllm: Defending large language models against jailbreaking attacks},
                        author={Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J},
                        journal={arXiv preprint arXiv:2310.03684},
                        year={2023}
                      }</p>
                </div>

                <!-- Adversarial Training Should Be Cast as a Non-Zero-Sum Game -->

                <div class="publication">
                    <img src="../img/paper-icons/nonzerosum.png" alt="Non-zero-sum AT" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Adversarial Training Should Be Cast as a Non-Zero-Sum Game
                        </p>
                        <p class="publication-authors">
                            Alexander Robey*, Fabian Latorre*, George J. Pappas, Hamed Hassani, Volkan Cevher
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2306.11035" target="_blank">arXiv</a> |
                                <a href="https://actu.epfl.ch/news/enhancing-ai-robustness-for-more-secure-and-reliab/" target="_blank">EPFL article</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                ICLR 2024
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2023adversarial,
                        title={Adversarial training should be cast as a non-zero-sum game},
                        author={Robey, Alexander and Latorre, Fabian and Pappas, George J. and Hassani, Hamed and Cevher, Volkan},
                        booktitle={International Conference on Learning Representations},
                        year={2024}
                      }</p>
                </div>

                <!-- Learning robust output control barrier functions from safe expert demonstrations -->

                <div class="publication">
                    <img src="../img/paper-icons/rocbf.png" alt="ROCBF" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Learning Robust Output Control Barrier Functions from Safe Expert Demonstrations
                        </p>
                        <p class="publication-authors">
                            Lars Lindemann, Alexander Robey, Lejun Jiang, Satyajeet Das, Stephen Tu, Nikolai Matni
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491341" target="_blank">arXiv</a> |
                                <a href="https://github.com/unstable-zeros/learning-rocbfs" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                OJCSYS 2024
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{lindemann2024learning,
                        title={Learning robust output control barrier functions from safe expert demonstrations},
                        author={Lindemann, Lars and Robey, Alexander and Jiang, Lejun and Das, Satyajeet and Tu, Stephen and Matni, Nikolai},
                        journal={IEEE Open Journal of Control Systems},
                        year={2024},
                        publisher={IEEE}
                      }</p>
                </div>

                <!-- Toward Certified Robustness Against Real-World Distribution Shifts -->

                <div class="publication">
                    <img src="../img/paper-icons/certified-distshift.png" alt="Distribution shift verification" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Toward Certified Robustness Against Real-World Distribution Shifts
                        </p>
                        <p class="publication-authors">
                            Haoze Wu*, Teruhiro Tagomori*, Alexander Robey*, Fengjun Yang*, Nikolai Matni, George J. Pappas, Hamed Hassani, Corina Pasareanu, Clark Barrett  
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://ieeexplore.ieee.org/abstract/document/10136136" target="_blank">arXiv</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                SaTML 2023
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{wu2023toward,
                        title={Toward certified robustness against real-world distribution shifts},
                        author={Wu, Haoze and Tagomori, Teruhiro and Robey, Alexander and Yang, Fengjun and Matni, Nikolai and Pappas, George and Hassani, Hamed and Pasareanu, Corina and Barrett, Clark},
                        booktitle={2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
                        pages={537--553},
                        year={2023},
                        organization={IEEE}
                      }</p>
                </div>

                <!-- Probable Domain Generalization via Quantile Risk Minimization -->

                <div class="publication">
                    <img src="../img/paper-icons/qrm.png" alt="QRM" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Probable Domain Generalization via Quantile Risk Minimization
                        </p>
                        <p class="publication-authors">
                            Cian Eastwood*, Alexander Robey*, Shashank Singh, Julius von Kügelgen, Hamed Hassani, George J. Pappas, Bernhard Schölkopf
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2207.09944" target="_blank">arXiv</a> |
                                <a href="https://github.com/facebookresearch/DomainBed" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                NeurIPS 2022
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{eastwood2022probable,
                        title={Probable domain generalization via quantile risk minimization},
                        author={Eastwood, Cian and Robey, Alexander and Singh, Shashank and Von K{\"u}gelgen, Julius and Hassani, Hamed and Pappas, George J. and Sch{\"o}lkopf, Bernhard},
                        journal={Advances in Neural Information Processing Systems},
                        volume={35},
                        pages={17340--17358},
                        year={2022}
                      }</p>
                </div>

                <!-- On the sample complexity of stability constrained imitation learning -->

                <div class="publication">
                    <img src="../img/paper-icons/imitationlearning.png" alt="Stable imitation learning" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            On the Sample Complexity of Stability Constrained Imitation Learning
                        </p>
                        <p class="publication-authors">
                            Stephen Tu, Alexander Robey, Tingnan Zhang, Nikolai Matni
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.mlr.press/v168/tu22a/tu22a.pdf" target="_blank">arXiv</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                L4DC 2022 (Oral)
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{tu2022sample,
                        title={On the sample complexity of stability constrained imitation learning},
                        author={Tu, Stephen and Robey, Alexander and Zhang, Tingnan and Matni, Nikolai},
                        booktitle={Learning for Dynamics and Control Conference},
                        pages={180--191},
                        year={2022},
                        organization={PMLR}
                      }</p>
                </div>

                <!-- Chordal Sparsity for Lipschitz Constant Estimation of Deep Neural Networks -->

                <div class="publication">
                    <img src="../img/paper-icons/chordal.png" alt="Chordally sparse LipSDP" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Chordal Sparsity for Lipschitz Constant Estimation of Deep Neural Networks
                        </p>
                        <p class="publication-authors">
                            Anton Xue, Lars Lindemann, Alexander Robey, Hamed Hassani, George J. Pappas, Rajeev Alur
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9993136" target="_blank">arXiv</a> |
                                <a href="https://github.com/AntonXue/nn-sdp" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                CDC 2022
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{xue2022chordal,
                        title={Chordal sparsity for lipschitz constant estimation of deep neural networks},
                        author={Xue, Anton and Lindemann, Lars and Robey, Alexander and Hassani, Hamed and Pappas, George J. and Alur, Rajeev},
                        booktitle={2022 IEEE 61st Conference on Decision and Control (CDC)},
                        pages={3389--3396},
                        year={2022},
                        organization={IEEE}
                      }</p>
                </div>

                <!-- Do Deep Networks Transfer Invariances Across Classes? -->

                <div class="publication">
                    <img src="../img/paper-icons/longtail.png" alt="Long-tailed robustness" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Do Deep Networks Transfer Invariances Across Classes?
                        </p>
                        <p class="publication-authors">
                            Allan Zhou*, Fahim Tajwar*, Alexander Robey, Tom Knowles, George J. Pappas, Hamed Hassani, Chelsea Finn
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2203.09739" target="_blank">arXiv</a> |
                                <a href="https://github.com/AllanYangZhou/generative-invariance-transfer" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                ICLR 2022
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{zhou2022deep,
                        title={Do deep networks transfer invariances across classes?},
                        author={Zhou, Allan and Tajwar, Fahim and Robey, Alexander and Knowles, Tom and Pappas, George J. and Hassani, Hamed and Finn, Chelsea},
                        booktitle={International Conference on Learning Representations},
                        year={2022}
                      }</p>
                </div>

                <!-- Probabilistically Robust Learning: Balancing Average- and Worst-case Performance -->

                <div class="publication">
                    <img src="../img/paper-icons/probrob.png" alt="Probabilistic robustness" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Probabilistically Robust Learning: Balancing Average- and Worst-case Performance
                        </p>
                        <p class="publication-authors">
                            Alexander Robey, Luiz F. O. Chamon, George J. Pappas, Hamed Hassani
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.mlr.press/v162/robey22a/robey22a.pdf" target="_blank">arXiv</a> |
                                <a href="https://github.com/arobey1/advbench" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                ICML 2022
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{robey2022probabilistically,
                        title={Probabilistically Robust Learning: Balancing Average and Worst-case Performance},
                        author={Robey, Alexander and Chamon, Luiz and Pappas, George J. and Hassani, Hamed},
                        booktitle={International Conference on Machine Learning},
                        pages={18667--18686},
                        year={2022},
                        organization={PMLR}
                      }</p>
                </div>

                <!-- Adversarial Robustness with Semi-Infinite Constrained Learning -->

                <div class="publication">
                    <img src="../img/paper-icons/semi-inf.png" alt="Semi-infinite robustness" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Adversarial Robustness with Semi-Infinite Constrained Learning
                        </p>
                        <p class="publication-authors">
                            Alexander Robey*, Luiz Chamon*, George J. Pappas, Hamed Hassani, Alejandro Ribeiro
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.neurips.cc/paper/2021/file/312ecfdfa8b239e076b114498ce21905-Paper.pdf" target="_blank">arXiv</a> |
                                <a href="https://github.com/arobey1/advbench" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                NeurIPS 2021
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2021adversarial,
                        title={Adversarial robustness with semi-infinite constrained learning},
                        author={Robey, Alexander and Chamon, Luiz and Pappas, George J. and Hassani, Hamed and Ribeiro, Alejandro},
                        journal={Advances in Neural Information Processing Systems},
                        volume={34},
                        pages={6198--6215},
                        year={2021}
                      }</p>
                </div>

                <!-- Model-based domain generalization -->

                <div class="publication">
                    <img src="../img/paper-icons/mbdg.png" alt="MBDG" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Model-Based Domain Generalization
                        </p>
                        <p class="publication-authors">
                            Alexander Robey, George J. Pappas, Hamed Hassani
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.neurips.cc/paper/2021/file/a8f12d9486cbcc2fe0cfc5352011ad35-Paper.pdf" target="_blank">arXiv</a> |
                                <a href="https://github.com/arobey1/mbdg" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                NeurIPS 2021
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2021model,
                        title={Model-based domain generalization},
                        author={Robey, Alexander and Pappas, George J. and Hassani, Hamed},
                        journal={Advances in Neural Information Processing Systems},
                        volume={34},
                        pages={20210--20229},
                        year={2021}
                      }</p>
                </div>

                <!-- Model-based domain generalization -->

                <div class="publication">
                    <img src="../img/paper-icons/cdcg.png" alt="CDCG" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Optimal Algorithms for Submodular Maximization With Distributed Constraints
                        </p>
                        <p class="publication-authors">
                            Alexander Robey, Arman Adibi, Brent Schlotfeldt, Hamed Hassani, George J. Pappas
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.mlr.press/v144/robey21a/robey21a.pdf" target="_blank">arXiv</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                L4DC 2021
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{robey2021optimal,
                        title={Optimal algorithms for submodular maximization with distributed constraints},
                        author={Robey, Alexander and Adibi, Arman and Schlotfeldt, Brent and Hassani, Hamed and Pappas, George J},
                        booktitle={Learning for Dynamics and Control},
                        pages={150--162},
                        year={2021},
                        organization={PMLR}
                      }</p>
                </div>

                <!-- Learning Robust Hybrid Control Barrier Functions for Uncertain Systems -->

                <div class="publication">
                    <img src="../img/paper-icons/compassgait.png" alt="RHCBF" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Learning Robust Hybrid Control Barrier Functions for Uncertain Systems
                        </p>
                        <p class="publication-authors">
                            Alexander Robey*, Lars Lindemann*, Stephen Tu, Nikolai Matni
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2101.06492" target="_blank">arXiv</a> |
                                <a href="https://github.com/unstable-zeros/learning-hcbfs" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                ADHS 2021
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2021learning,
                        title={Learning robust hybrid control barrier functions for uncertain systems},
                        author={Robey, Alexander and Lindemann, Lars and Tu, Stephen and Matni, Nikolai},
                        journal={IFAC-PapersOnLine},
                        volume={54},
                        number={5},
                        pages={1--6},
                        year={2021},
                        publisher={Elsevier}
                      }</p>
                </div>

                <!-- Learning Hybrid Control Barrier Functions from Data -->

                <div class="publication">
                    <img src="../img/paper-icons/hybrid.png" alt="HCBF" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Learning Hybrid Control Barrier Functions from Data
                        </p>
                        <p class="publication-authors">
                            Lars Lindemann, Haimin Hu, Alexander Robey, Hanwen Zhang, Dimos V. Dimarogonas, Stephen Tu, Nikolai Matni
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.mlr.press/v155/lindemann21a/lindemann21a.pdf" target="_blank">arXiv</a> |
                                <a href="https://github.com/unstable-zeros/learning-hcbfs" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                CoRL 2020
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{lindemann2021learning,
                        title={Learning hybrid control barrier functions from data},
                        author={Lindemann, Lars and Hu, Haimin and Robey, Alexander and Zhang, Hanwen and Dimarogonas, Dimos and Tu, Stephen and Matni, Nikolai},
                        booktitle={Conference on robot learning},
                        pages={1351--1370},
                        year={2021},
                        organization={PMLR}
                      }</p>
                </div>

                <!-- Learning Control Barrier Functions from Expert Demonstrations -->

                <div class="publication">
                    <img src="../img/paper-icons/cbf.png" alt="CBF" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Learning Control Barrier Functions from Expert Demonstrations
                        </p>
                        <p class="publication-authors">
                            Alexander Robey*, Haimin Hu*, Lars Lindemann, Hanwen Zhang, Dimos V. Dimarogonas, Stephen Tu, Nikolai Matni
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2004.03315" target="_blank">arXiv</a> |
                                <a href="https://github.com/unstable-zeros/learning-cbfs" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                CDC 2020
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@inproceedings{robey2020learning,
                        title={Learning control barrier functions from expert demonstrations},
                        author={Robey, Alexander and Hu, Haimin and Lindemann, Lars and Zhang, Hanwen and Dimarogonas, Dimos V and Tu, Stephen and Matni, Nikolai},
                        booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},
                        pages={3717--3724},
                        year={2020},
                        organization={IEEE}
                      }</p>
                </div>

                <!-- Provable Tradeoffs in Adversarially Robust Classification -->

                <div class="publication">
                    <img src="../img/paper-icons/adv-tradeoff.png" alt="Adversarial trade-off" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Provable Tradeoffs in Adversarially Robust Classification
                        </p>
                        <p class="publication-authors">
                            Edgar Dobriban, Hamed Hassani, David Hong, Alexander Robey
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2006.05161" target="_blank">arXiv</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Trans. on Information Theory
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{dobriban2023provable,
                        title={Provable tradeoffs in adversarially robust classification},
                        author={Dobriban, Edgar and Hassani, Hamed and Hong, David and Robey, Alexander},
                        journal={IEEE Transactions on Information Theory},
                        year={2023},
                        publisher={IEEE}
                      }</p>
                </div>

                <!-- Model-based robust deep learning: Generalizing to natural, out-of-distribution data -->

                <div class="publication">
                    <img src="../img/paper-icons/mbrdl.png" alt="MBRDL" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data
                        </p>
                        <p class="publication-authors">
                            Alexander Robey, Hamed Hassani, George J. Pappas
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://arxiv.org/pdf/2005.10247" target="_blank">arXiv</a> |
                                <a href="https://github.com/arobey1/mbrdl" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                arXiv
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2020model,
                        title={Model-based robust deep learning: Generalizing to natural, out-of-distribution data},
                        author={Robey, Alexander and Hassani, Hamed and Pappas, George J},
                        journal={arXiv preprint arXiv:2005.10247},
                        year={2020}
                      }</p>
                </div>

                <!-- Efficient and accurate estimation of lipschitz constants for deep neural networks -->

                <div class="publication">
                    <img src="../img/paper-icons/lipsdp.png" alt="LipSDP" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks
                        </p>
                        <p class="publication-authors">
                            Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, George J. Pappas
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://proceedings.neurips.cc/paper/2019/file/95e1533eb1b20a97777749fb94fdb944-Paper.pdf" target="_blank">arXiv</a> |
                                <a href="https://github.com/arobey1/LipSDP" target="_blank">code</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                NeurIPS 2019 (Spotlight)
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{fazlyab2019efficient,
                        title={Efficient and accurate estimation of lipschitz constants for deep neural networks},
                        author={Fazlyab, Mahyar and Robey, Alexander and Hassani, Hamed and Morari, Manfred and Pappas, George},
                        journal={Advances in neural information processing systems},
                        volume={32},
                        year={2019}
                      }</p>
                </div>

                <!-- Optimal Physical Preprocessing for Example-Based Super-Resolution -->

                <div class="publication">
                    <img src="../img/paper-icons/fourier-ptychography.jpeg" alt="Fourier Ptychography" class="publication-img">
                    <div class="publication-details">
                        <p class="publication-title">
                            Optimal Physical Preprocessing for Example-Based Super-Resolution
                        </p>
                        <p class="publication-authors">
                            Alexander Robey and Vidya Ganapati
                        </p>
                        <div class="publication-links-container">
                            <span class="publication-links">
                                <a href="https://opg.optica.org/directpdfaccess/db726962-7d67-4dba-b4592783d16bdb56_401259/oe-26-24-31333.pdf?da=1&id=401259&seq=0&mobile=no" target="_blank">arXiv</a> |
                                <a href="javascript:void(0);" class="bibtex-link">bibtex</a>
                            </span>
                            <span class="publication-venue">
                                Optics Express
                            </span>
                        </div>
                    </div>
                </div>
                <div class="bibtex-box" style="display: none;">
                    <p>@article{robey2018optimal,
                        title={Optimal physical preprocessing for example-based super-resolution},
                        author={Robey, Alexander and Ganapati, Vidya},
                        journal={Optics Express},
                        volume={26},
                        number={24},
                        pages={31333--31350},
                        year={2018},
                        publisher={Optica Publishing Group}
                      }</p>
                </div>

        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const bibtexLinks = document.querySelectorAll('.bibtex-link');
        
            bibtexLinks.forEach(link => {
                link.addEventListener('click', function () {
                    // Get the next sibling of the publication (the bibtex box)
                    const publication = this.closest('.publication').nextElementSibling;
        
                    // Check if the BibTeX box is hidden, then toggle visibility
                    if (publication.style.display === 'none' || !publication.style.display) {
                        publication.style.display = 'block';
                    } else {
                        publication.style.display = 'none';
                    }
                });
            });
        });
    </script>
        
</body>
</html>
