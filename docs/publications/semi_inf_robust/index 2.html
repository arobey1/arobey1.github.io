<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author"
    content="Alex Robey ">
<meta name="description"
    content="Abstract. Despite strong performance in numerous applications, the fragility of deep learning to input perturbations has raised serious questions about its use in safety-critical domains. While adversarial training can mitigate this issue in practice, state-of- the-art methods are increasingly application-dependent, heuristic in nature, and suffer from fundamental trade-offs between nominal performance and robustness. Moreover, the problem of finding worst-case perturbations is non-convex and underparameterized, both of which engender a non-favorable optimization landscape." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://arobey1.github.io/publications/semi_inf_robust/" />


<title>
    
    Adversarial Robustness with Semi-Infinite Constrained Learning :: Alex Robey 
    
</title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css" rel="stylesheet"
    type="text/css">



<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



<link rel="stylesheet" href="https://arobey1.github.io/main.min.f4c2daf2832ae65007bcc18dc621f49f9f67ef0ef34d55eabd4fd45f6eed4c00.css">



    <link rel="apple-touch-icon" sizes="180x180" href="https://arobey1.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://arobey1.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://arobey1.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://arobey1.github.io/site.webmanifest">
    <link rel="mask-icon" href="https://arobey1.github.io/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://arobey1.github.io/favicon.ico">
    <meta name="msapplication-TileColor" content="">
    <meta name="theme-color" content="">

<meta itemprop="name" content="Adversarial Robustness with Semi-Infinite Constrained Learning">
<meta itemprop="description" content="Abstract. Despite strong performance in numerous applications, the fragility of deep learning to input perturbations has raised serious questions about its use in safety-critical domains. While adversarial training can mitigate this issue in practice, state-of- the-art methods are increasingly application-dependent, heuristic in nature, and suffer from fundamental trade-offs between nominal performance and robustness. Moreover, the problem of finding worst-case perturbations is non-convex and underparameterized, both of which engender a non-favorable optimization landscape."><meta itemprop="datePublished" content="2021-11-26T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-12-07T08:57:15-05:00" />
<meta itemprop="wordCount" content="628"><meta itemprop="image" content="https://arobey1.github.io/"/>
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://arobey1.github.io/"/>

<meta name="twitter:title" content="Adversarial Robustness with Semi-Infinite Constrained Learning"/>
<meta name="twitter:description" content="Abstract. Despite strong performance in numerous applications, the fragility of deep learning to input perturbations has raised serious questions about its use in safety-critical domains. While adversarial training can mitigate this issue in practice, state-of- the-art methods are increasingly application-dependent, heuristic in nature, and suffer from fundamental trade-offs between nominal performance and robustness. Moreover, the problem of finding worst-case perturbations is non-convex and underparameterized, both of which engender a non-favorable optimization landscape."/>




<meta property="article:published_time" content="2021-11-26 00:00:00 &#43;0000 UTC" />






    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://arobey1.github.io/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">&gt;</span>
            <span class="logo__text">Alex Robey</span>
            <span class="logo__cursor" style=
                  "visibility:hidden;
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://arobey1.github.io/about/">About</a></li><li><a href="https://arobey1.github.io/cv/">CV</a></li><li><a href="https://arobey1.github.io/posts/">Posts</a></li><li><a href="https://arobey1.github.io/publications/">Publications</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
                <span class="theme-toggle not-selectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
   <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
   3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
   13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
 </svg></span>
            <script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

        </span>
    </span>
</header>



            <div class="content">
                
    <main class="post">

        <div class="post-info">
            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>3 minutes

            

            </p>
        </div>

        <article>
            <h1 class="post-title"><a href="https://arobey1.github.io/publications/semi_inf_robust/">Adversarial Robustness with Semi-Infinite Constrained Learning</a></h1>
            <h3 >Alexander Robey, Luiz F. O. Chamon, George J. Pappas, Hamed Hassani, Alejandro Ribeiro</h3>

            

            <div class="post-content">
                <p><strong>Abstract.</strong>  Despite strong performance in numerous applications, the fragility of deep learning to input perturbations has raised serious questions about its use in safety-critical domains. While adversarial training can mitigate this issue in practice, state-of- the-art methods are increasingly application-dependent, heuristic in nature, and suffer from fundamental trade-offs between nominal performance and robustness. Moreover, the problem of finding worst-case perturbations is non-convex and underparameterized, both of which engender a non-favorable optimization landscape. Thus, there is a gap between the theory and practice of adversarial training, particularly with respect to when and why adversarial training works. In this paper, we take a constrained learning approach to address these questions and to provide a theoretical foundation for robust learning. In particular, we leverage semi-infinite optimization and non-convex duality theory to show that adversarial training is equivalent to a statistical problem over perturbation distributions, which we characterize completely. Notably, we show that a myriad of previous robust training techniques can be recovered for particular, sub-optimal choices of these distributions. Using these insights, we then propose a hybrid Langevin Monte Carlo approach of which several common algorithms (e.g., PGD) are special cases. Finally, we show that our approach can mitigate the trade-off between nominal and robust performance, yielding state-of-the-art results on MNIST and CIFAR-10. Our code is available at: <a href="https://github.com/arobey1/advbench">https://github.com/arobey1/advbench</a>.</p>
<hr>
<h2 id="summary">Summary</h2>
<p>In this paper, we revisit the classicial problem of training a classifier to be robust against imperceptible perturbations of data.  In a litany of past work, researchers have shown that such perturbations can cause state-of-the-art classifiers to misclassify data with high confidence.  Indeed, this problem has received a somewhat staggering amount of attention over the last few years, in part because it reveals a fundamental discrepancy between how deep neural networks and humans learn.</p>
<p>The goal of this post is threefold:</p>
<ol>
<li>First, I&rsquo;ll introduce the problem setting for (adversarially) robust deep learning.</li>
<li>Next, I&rsquo;ll formalize the setting.</li>
</ol>
<h3 id="a-primer-on-image-classification">A primer on image classification</h3>
<p>In image classification tasks, we generally assume that our data consists of images $x\in\mathbb{R}^d$, where $d$ is the number of pixels in the image, and corresponding labels $y\in\mathcal{Y} := \{1, \dots, k\}$, where $y$ captures the contents of the image.</p>
<p><img src="../../gifs/panda_data.gif" alt="Panda"></p>
<p>Furthermore, we assume that our data is distributed according to an <em>unknown</em> joint distribution $\mathcal{D}$.  In standard (i.e. non-robust) supervised learning, our job is to find a classifier which can correctly predict the label $y$ of the corresponding image $x$ when $(x,y)\sim\mathcal{D}$.  That is, given a family of classifiers $f_\theta$ parameterized by a vector $\theta\in\Theta\subset\mathbb{R}^n$, we&rsquo;re looking for a classifier $f_{\theta^\star}$ such that</p>
<p>$$f_{\theta^\star}(x) = y \quad\text{whenever}\quad (x,y)\sim\mathcal{D}.$$</p>
<p>The problem of obtaining such a classifier can be formalized via the following <em>risk minimization</em> problem:</p>
<p>$$P^\star_\text{std} \triangleq \min_{\theta\in\Theta} \mathbb{E}_{(x,y)\sim\mathcal{D}} \left[ \ell(f_\theta(x),y) \right] \tag{P-STD}$$</p>
<p>where $\ell:\mathcal{Y}\times\mathcal{Y}\to\mathbb{R}_{\geq0}$ is a suitable loss function (e.g. the cross-entropy or squared loss) and (P-STD) denotes the optimal value of the problem.  In words, this optimization problem says that we will select a parameter $\theta$ which minimizes the average loss over the data distribution $\mathcal{D}$.</p>
<h3 id="formulating-the-robust-training-problem">Formulating the robust training problem</h3>
<p>In the setting of adversarial robustness, we consider a slightly different problem.  Rather than directly classifying images $x$ drawn according to $\mathcal{D}$, we assume that there is an <em>adversary</em> which can perturb the data via a small, additive perturbation.  To make this formal, we assume that an adversary can apply a perturbation $\delta\in\Delta$ via $x\mapsto x+\delta =: x'$, where $\Delta$ denotes a pre-specified <em>perturbation set</em>.  For instance, one commone perturbation set if a norm-ball of radius $\epsilon$:</p>
<p>$$\Delta = \{ \delta\in\mathbb{R}^d : ||\delta||_\infty \leq \epsilon \}.$$</p>
<p>This particualr choice of perturbation set is appealing because it allows an adversary to additively perturb an image in a pixle-wise fashion.</p>
<p><img src="../../gifs/panda_adv.gif" alt="Panda"></p>
<p>Just as in the non-adversarial setting, we can again formulate the problem of</p>
<p>$$\min_\theta \mathbb{E}_{(x,y)} \left[ \max_{\delta\in\Delta} \ell(f_\theta(x+\delta),y) \right]$$</p>

                
            </div>
        </article>

        <hr />

        <div class="post-info">

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>628 Words</p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2021-11-25 19:00</p>
                <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-git-commit"><circle cx="12" cy="12" r="4"></circle><line x1="1.05" y1="12" x2="7" y2="12"></line><line x1="17.01" y1="12" x2="22.96" y2="12"></line></svg><a href="https://github.com/arobey1e3bfce9b0a3cce0ec41aab3dca6f5d1f794bab8d" target="_blank" rel="noopener">e3bfce9</a> @ 2021-12-07</p>
        </div>

        
            <div class="pagination">
                <div class="pagination__title">
                    <span class="pagination__title-h"></span>
                    <hr />
                </div>

                <div class="pagination__buttons">
                    

                    
                        <span class="button next">
                            <a href="https://arobey1.github.io/publications/mbdg/">
                                <span class="button__text">Model-Based Domain Generalization</span>
                                <span class="button__icon">â†’</span>
                            </a>
                        </span>
                    
                </div>
            </div>
        

        
    </main>

            </div>

            
                <footer class="footer">
    
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2021</span>
            <span><a href="https://arobey1.github.io/">Alex Robey</a></span>
            
        </div>
    </div>
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://arobey1.github.io/bundle.min.599099f1f14b78b657d524b28e10e0c5098e7cd46e9c7aed73d577068a276c3ff1bb234cbf29cb313333e83cf411727b43157c91ce5b809e2ffc81664614608e.js" integrity="sha512-WZCZ8fFLeLZX1SSyjhDgxQmOfNRunHrtc9V3BoonbD/xuyNMvynLMTMz6Dz0EXJ7QxV8kc5bgJ4v/IFmRhRgjg=="></script>



    </body>
</html>
